{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e1c7d52e4ad9c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools import mask as coco_mask\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "from groundingdino.util import box_ops\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from segment_anything.utils.amg import (mask_to_rle_pytorch, \n",
    "                                        rle_to_mask,\n",
    "                                        area_from_rle,\n",
    "                                        remove_small_regions,\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925c44d-2656-4544-9469-9fc44ab44a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAM_CHECKPOINT = \"/scratch/gpfs/eh0560/segment-anything/sam_models/sam_vit_h_4b8939.pth\"\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "DINO_MODEL_PATH = \"/scratch/gpfs/eh0560/GroundingDINO/models/groundingdino_swinb_cogcoor.pth\"\n",
    "DINO_CONFIG_PATH = \"/scratch/gpfs/eh0560/GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py\"\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adaf1c-10be-4c22-a536-88d5a6636ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sam_model(checkpoint, model_type, device):\n",
    "    sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "    return sam.to(device), SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bba99b-cc4c-4d17-aff2-4a31d64b1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_model, sam_predictor = load_sam_model(SAM_CHECKPOINT, MODEL_TYPE, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f06caa-3921-47a7-a120-07a744c03c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_model = load_model(DINO_CONFIG_PATH, DINO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2806b-4826-4b23-8f7a-64213cd4a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"/scratch/gpfs/RUSTOW/deskewing_datasets/images/cudl_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46996fa-3984-431e-ba1d-57d195ed37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(directory):\n",
    "    jpg_paths = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith('.jpg'):\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                jpg_paths.append(full_path)\n",
    "\n",
    "    return jpg_paths#%%\n",
    "cudl_images = get_images(IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eba579-43dc-4d91-b4a5-89b859390165",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = cudl_images[random.randint(0, len(cudl_images))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c7511-b102-4801-9e64-c5152535740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PROMPT = \"scanned document\"\n",
    "BOX_THRESHOLD = 0.45\n",
    "TEXT_THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42286c58-a8df-45e7-b6c9-38f21afa291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source, image = load_image(image_path)\n",
    "boxes, logits, phrases = predict(dino_model, image, TEXT_PROMPT, BOX_THRESHOLD, TEXT_THRESHOLD)\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389a459-56b9-4ca0-8fb5-e263f8ebbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_predictor.set_image(image_source)\n",
    "\n",
    "H, W, _ = image_source.shape\n",
    "boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
    "transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, image_source.shape[:2]).to(DEVICE)\n",
    "\n",
    "masks, iou_preds, logits = sam_predictor.predict_torch(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    boxes=transformed_boxes,\n",
    "    multimask_output=False\n",
    ")\n",
    "\n",
    "flattened_mask = masks.sum(dim=1)\n",
    "masks = (flattened_mask == True).cpu().numpy()\n",
    "# get first mask since batch size is 1\n",
    "mask = masks[0]\n",
    "\n",
    "mask, _ = remove_small_regions(mask, 100 * 100, \"holes\")\n",
    "mask, _ = remove_small_regions(mask, 100 * 100, \"islands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f84469-53c0-4921-ae79-cfb978529b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rle = coco_mask.encode(np.asfortranarray(mask))\n",
    "# mask = coco_mask.decode(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60fdd4-89e9-4ec5-81ab-f24a284eb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mask(mask, image, random_color=True):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    \n",
    "    annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n",
    "    mask_image_pil = Image.fromarray((mask_image * 255).astype(np.uint8)).convert(\"RGBA\")\n",
    "    \n",
    "    return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))\n",
    "\n",
    "def remove_background(image, mask):\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    if mask.ndim == 2:\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    alpha_channel = mask * 255 \n",
    "    rgba_image = np.concatenate([image, alpha_channel], axis=-1)\n",
    "    \n",
    "    return rgba_image\n",
    "\n",
    "annotated_frame_with_mask = visualize_mask(mask, annotated_frame)\n",
    "image_without_background = remove_background(image_source, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ff833-4667-4a40-a138-0cd2d860138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(image_without_background)\n",
    "# Image.fromarray(annotated_frame_with_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env [~/.conda/envs/torch_env/]",
   "language": "python",
   "name": "conda_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

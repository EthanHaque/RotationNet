{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools import mask as coco_mask\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "from groundingdino.util import box_ops\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from segment_anything.utils.amg import (mask_to_rle_pytorch, \n",
    "                                        rle_to_mask,\n",
    "                                        area_from_rle,\n",
    "                                        remove_small_regions,\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae25b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAM_CHECKPOINT = \"/scratch/gpfs/eh0560/segment-anything/sam_models/sam_vit_h_4b8939.pth\"\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "DINO_MODEL_PATH = \"/scratch/gpfs/eh0560/GroundingDINO/models/groundingdino_swinb_cogcoor.pth\"\n",
    "DINO_CONFIG_PATH = \"/scratch/gpfs/eh0560/GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py\"\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c667b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sam_model(checkpoint, model_type, device):\n",
    "    sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "    return sam.to(device), SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6df65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sam_model, sam_predictor = load_sam_model(SAM_CHECKPOINT, MODEL_TYPE, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be05512",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_model = load_model(DINO_CONFIG_PATH, DINO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc49b63-cbfc-4615-ab58-9ea522d91c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"/scratch/gpfs/RUSTOW/deskewing_datasets/images/cudl_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545bb90-7c1d-40c5-950c-531c755cd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(directory):\n",
    "    jpg_paths = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith('.jpg'):\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                jpg_paths.append(full_path)\n",
    "\n",
    "    return jpg_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26318f62-eb22-495d-b000-2ea822275d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudl_images = get_images(IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c56f2-7fc4-44c4-8ac0-71dad0e79b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = cudl_images[random.randint(0, len(cudl_images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790655c1-fb7c-4a77-9663-aaad9eb9f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PROMPT = \"scanned document\"\n",
    "BOX_THRESHOLD = 0.45\n",
    "TEXT_THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source, image = load_image(image_path)\n",
    "boxes, logits, phrases = predict(dino_model, image, TEXT_PROMPT, BOX_THRESHOLD, TEXT_THRESHOLD)\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_predictor.set_image(image_source)\n",
    "\n",
    "H, W, _ = image_source.shape\n",
    "boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
    "transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, image_source.shape[:2]).to(DEVICE)\n",
    "\n",
    "masks, iou_preds, logits = sam_predictor.predict_torch(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    boxes=transformed_boxes,\n",
    "    multimask_output=False\n",
    ")\n",
    "\n",
    "flattened_mask = masks.sum(dim=1)\n",
    "masks = (flattened_mask == True).cpu().numpy()\n",
    "# get first mask since batch size is 1\n",
    "mask = masks[0]\n",
    "\n",
    "mask, _ = remove_small_regions(mask, 100 * 100, \"holes\")\n",
    "mask, _ = remove_small_regions(mask, 100 * 100, \"islands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf2a20-da71-418a-97f7-297090c45b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rle = coco_mask.encode(np.asfortranarray(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f158eac-2bfc-4c1e-b8fa-49e3605f0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = coco_mask.decode(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mask(mask, image, random_color=True):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    \n",
    "    annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n",
    "    mask_image_pil = Image.fromarray((mask_image * 255).astype(np.uint8)).convert(\"RGBA\")\n",
    "    \n",
    "    return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image, mask):\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    if mask.ndim == 2:\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    alpha_channel = mask * 255 \n",
    "    rgba_image = np.concatenate([image, alpha_channel], axis=-1)\n",
    "    \n",
    "    return rgba_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e34a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_frame_with_mask = visualize_mask(mask, annotated_frame)\n",
    "image_without_background = remove_background(image_source, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac742b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(image_without_background)\n",
    "# Image.fromarray(annotated_frame_with_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d767696-9ff8-4dad-969b-f7ebfa42ae25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env [~/.conda/envs/torch_env/]",
   "language": "python",
   "name": "conda_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

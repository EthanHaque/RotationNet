{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools import mask as coco_mask\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "from groundingdino.util import box_ops\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from segment_anything.utils.amg import mask_to_rle_pytorch, rle_to_mask, area_from_rle, remove_small_regions\n",
    "\n",
    "\n",
    "# 2. Constants and Global Variables\n",
    "SAM_CHECKPOINT = \"/scratch/gpfs/eh0560/segment-anything/sam_models/sam_vit_h_4b8939.pth\"\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "DINO_MODEL_PATH = \"/scratch/gpfs/eh0560/GroundingDINO/models/groundingdino_swinb_cogcoor.pth\"\n",
    "DINO_CONFIG_PATH = \"/scratch/gpfs/eh0560/GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py\"\n",
    "DEVICE = \"cuda\"\n",
    "IMAGES_DIR = \"/scratch/gpfs/RUSTOW/deskewing_datasets/images/cudl_images\"\n",
    "TEXT_PROMPT = \"scanned document\"\n",
    "BOX_THRESHOLD = 0.45\n",
    "TEXT_THRESHOLD = 0.25\n",
    "\n",
    "\n",
    "# 3. Utility Functions\n",
    "def load_sam_model(checkpoint, model_type, device):\n",
    "    sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "    return sam.to(device), SamPredictor(sam)\n",
    "\n",
    "def get_images(directory):\n",
    "    return [os.path.join(dirpath, filename) for dirpath, _, filenames in os.walk(directory) for filename in filenames if filename.lower().endswith('.jpg')]\n",
    "\n",
    "def visualize_mask(mask, image, random_color=True):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0) if random_color else np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    mask_image = (mask.reshape(*mask.shape, 1) * color.reshape(1, 1, -1))\n",
    "    annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n",
    "    mask_image_pil = Image.fromarray((mask_image * 255).astype(np.uint8)).convert(\"RGBA\")\n",
    "    return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))\n",
    "\n",
    "def remove_background(image, mask):\n",
    "    alpha_channel = (mask > 0).astype(np.uint8) * 255\n",
    "    return np.concatenate([image, alpha_channel], axis=-1)\n",
    "\n",
    "\n",
    "# 4. Main Function\n",
    "def main():\n",
    "    # Load models\n",
    "    sam_model, sam_predictor = load_sam_model(SAM_CHECKPOINT, MODEL_TYPE, DEVICE)\n",
    "    dino_model = load_model(DINO_CONFIG_PATH, DINO_MODEL_PATH)\n",
    "    \n",
    "    cudl_images = get_images(IMAGES_DIR)\n",
    "    image_path = random.choice(cudl_images)\n",
    "    image_source, image = load_image(image_path)\n",
    "    \n",
    "    boxes, logits, phrases = predict(dino_model, image, TEXT_PROMPT, BOX_THRESHOLD, TEXT_THRESHOLD)\n",
    "    \n",
    "    sam_predictor.set_image(image_source)\n",
    "    H, W, _ = image_source.shape\n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
    "    transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, image_source.shape[:2]).to(DEVICE)\n",
    "    masks, _, _ = sam_predictor.predict_torch(point_coords=None, point_labels=None, boxes=transformed_boxes, multimask_output=False)\n",
    "    \n",
    "    mask = (masks.sum(dim=1) == True).cpu().numpy()[0]\n",
    "    mask, _ = remove_small_regions(mask, 10000, \"holes\")\n",
    "    mask, _ = remove_small_regions(mask, 10000, \"islands\")\n",
    "    \n",
    "    annotated_frame_with_mask = visualize_mask(mask, image_source)\n",
    "    image_without_background = remove_background(image_source, mask)\n",
    "    \n",
    "    # Display images (for demonstration, the next steps depend on how the visualization is handled)\n",
    "    Image.fromarray(image_without_background).show()\n",
    "    Image.fromarray(annotated_frame_with_mask).show()\n",
    "\n",
    "\n",
    "# 5. Execution Point\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b6e1c7d52e4ad9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env [~/.conda/envs/torch_env/]",
   "language": "python",
   "name": "conda_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
